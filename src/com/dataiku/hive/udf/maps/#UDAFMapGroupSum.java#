package com.dataiku.hive.udf.maps;

import scala.Tuple2;

import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
import org.apache.hadoop.hive.ql.metadata.HiveException;
import org.apache.hadoop.hive.ql.parse.SemanticException;
import org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDAFResolver;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator;
import org.apache.hadoop.hive.serde2.lazy.LazyFactory;
import org.apache.hadoop.hive.serde2.lazy.LazyMap;
import org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyMapObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.*;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;

import java.rmi.MarshalledObject;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;

/**
 * Group a set of map and sum identical integer keys
 */
public class UDAFMapGroupSum extends AbstractGenericUDAFResolver {
    @Override
    public GenericUDAFEvaluator getEvaluator(TypeInfo[] tis) throws SemanticException {
        if (tis.length != 1) {
            throw new UDFArgumentTypeException(tis.length - 1, "Exactly one argument is expected.");
        }
        return new MapGroupSumEvaluator();
    }

    public static class MapGroupSumEvaluator extends GenericUDAFEvaluator {
        private MapObjectInspector originalDataOI;
        private IntObjectInspector valueOI;
        private StringObjectInspector keyOI;


        @Override
        public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {
            super.init(m, parameters);

            originalDataOI = (MapObjectInspector) parameters[0];
            keyOI = (StringObjectInspector) originalDataOI.getMapKeyObjectInspector();
            valueOI = (IntObjectInspector) originalDataOI.getMapValueObjectInspector();
            return ObjectInspectorFactory.getStandardMapObjectInspector(PrimitiveObjectInspectorFactory.javaStringObjectInspector,
                        PrimitiveObjectInspectorFactory.javaIntObjectInspector);
        }

        static class MapBuffer extends AbstractAggregationBuffer {
            Map<String, Integer> map = new HashMap<String, Integer>();
        }

        @Override
        public void reset(AggregationBuffer ab) throws HiveException {
            ((MapBuffer) ab).map.clear();
        }

        @Override
        public AggregationBuffer getNewAggregationBuffer() throws HiveException {
            return new MapBuffer();
        }

        protected void mapAppend(Map<String, Integer> m, Map<Object, Object> from)  {
            if (from == null) {
                return;
            }
            for(Map.Entry<Object, Object> entry : from.entrySet()) {
                Object okey = entry.getKey();
                Object ovalue = entry.getValue();
                if (okey == null || ovalue == null) continue;
                String key = keyOI.getPrimitiveJavaObject(entry.getKey());
                Integer value = valueOI.get(entry.getValue());
                if (m.containsKey(key)) {
                    m.put(key, m.get(key) + value);
                } else {
                    m.put(key, value);
                }
            }
        }

        @Override
        public void iterate(AggregationBuffer ab, Object[] parameters)  throws HiveException {
	    Map<Object,Object> finalMap = new HashMap<Object,Object>();

            assert (parameters.length == 1);
            Object p = parameters[0];

	    scala.collection.immutable.Map m = (scala.collection.immutable.Map) p;
	    
	    scala.collection.Iterator iter = m.keysIterator();
	    
	    while(iter.hasNext()){
		String key = (String)iter.next();
		finalMap.put(key, (Integer)m.get(key).get());
	    }
	    
            if (p != null) {
                MapBuffer agg = (MapBuffer) ab;
                Map<Object, Object> o = (Map<Object, Object>) this.originalDataOI.getMap(finalMap);
                mapAppend(agg.map, o);
            }
        }

        @Override
        public Object terminatePartial(AggregationBuffer ab) throws HiveException {
            MapBuffer agg = (MapBuffer) ab;
	    return new HashMap<Object,Object>(agg.map);
        }

        @Override
        public void merge(AggregationBuffer ab, Object p) throws HiveException {
            MapBuffer agg = (MapBuffer) ab;
            @SuppressWarnings("unchecked")
            Map<Object, Object> obj = (Map<Object, Object>) this.originalDataOI.getMap(p);
            mapAppend(agg.map, obj);
        }

        @Override
        public Object terminate(AggregationBuffer ab)  throws HiveException {
            MapBuffer agg = (MapBuffer) ab;
	    return new HashMap<Object,Object>(agg.map);
        }
    }
}
